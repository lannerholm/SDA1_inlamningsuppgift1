---
title: "Statistik och dataanalys I, 15 hp "
subtitle: "Inl칛mningsuppgift 1"
author: 
- Namn Daniel L칛nnerholm Palm
- Namn Alice L칬nnerblad
- Namn Anton Bylin
date: last-modified
format: 
  html:
    self-contained: true
  pdf: default  
  docx: default
toc: true
language: 
  title-block-author-single: " "
toc-title-document: "Inneh친ll"
crossref-fig-title: "Figur"
theme: Superhero
title-block-banner-color: Primary
title-block-published: "Publicerad"
callout-warning-caption: "Varning"
callout-note-caption: "Observera"
callout-tip-caption: "Tips"
editor: visual
---

::: callout-warning
Den h칛r inl칛mningsuppgiften f칬ruts칛tter att f칬ljande paket finns installerade:

-   `mosaic`

-   `dplyr`

-   `geosphere`

-   `leaflet`

Paket kan installeras via kommandot `install.packages('packagename')`, d칛r `'packagename'` 칛r namnet p친 paketet, t.ex `'mosaic'`.
:::

## Introduktion

I den f칬rsta inl칛mningsuppgiften ska ni sj칛lvst칛ndigt i grupper om tre analysera ett dataset i programmeringsspr친ket R. Till skillnad fr친n datorlaborationerna finns det minimalt med kodexempel. Datorlaborationerna g친r igenom de flesta momenten som behandlas i inl칛mningsuppgiften, s친 se till att g칬ra klart dessa innan.

------------------------------------------------------------------------

::: callout-note
### Instruktioner

I denna inl칛mningsuppgift ska ni analysera ett datamaterial som inneh친ller en m칛ngd olika variabler fr친n en totalunders칬kning[^1] i Boston 1970 som aggregerats till ca 500 censusdistrikt. Datasetet f칬rekommer i m친nga olika varianter. H칛r anv칛nder vi en modifierad version[^2] av originaldata[^3] som anv칛nts i en studie[^4] d칛r f칬rfattarna predikterar medianhuspriset i ett censusdistrikt givet en upps칛ttning f칬rklarande variabler.

F칬ljande variabler finns i datasetet `boston_census_data.Rdata` ([ladda ner](https://github.com/StatisticsSU/SDA1/blob/main/assignments/assignment1/Boston_census_data.RData?raw=true)) f칬r 480 observationer. Notera att en observation motsvarar ett censusdistrikt:

-   `town`: Stadsdel.
-   `longitude`: Longitud koordinat.
-   `latitude`: Latitud koordinat.
-   `median_home_value`: Medianhuspriset (enhet 1K USD).
-   `crime_rate`: Brott (per 1000 inv친nare).
-   `zoned_25k_p`: Andel av stadsdelens bostadsmark 칛mnad f칬r marklotter st칬rre 칛n 25000 kvadratfot.
-   `indust_p`: Andel tunnland 칛gd av f칬retag utanf칬r detaljhandel.
-   `borders_charles`: Charles River dummy variabel (= 1 om omr친det gr칛nsar till floden, 0 annars).
-   `NOx`: Koncentration av kv칛veoxider (andelar per 10 miljon).
-   `n_rooms_avg`: Genomsnitt antal rum i 칛gda bost칛der.
-   `before_1940_p`: Andel 칛gda bost칛der byggda f칬re 1940.
-   `employ_dist`: Viktat avst친nd till fem arbetsf칬rmedlingscentra i Boston.
-   `radial_access`: Index som m칛ter tillg친ng till stadsmotorv칛gar.
-   `tax_rate`: Fastighetsskatt per 10000 USD.
-   `pupil_teacher_ratio`: L칛rart칛thet m칛tt som elev per l칛rare.
-   `lower_stat_pct`: Procentandel underklass definerad som en av tv친: (i) andel vuxna utan gymnasieutbildning eller (ii) andel m칛n som genomf칬r okvalificerat arbete.

Bland de f칬rklarande variablerna som anv칛nts i studien (ej med i datasetet) finns en icke-linj칛r interaktion av latitud och longitud koordinaterna f칬r att modellera medianhuspriset spatiellt (dvs deras modell anv칛nder censusdistriktens geografiska platser f칬r att f친nga den spatiella variationen i huspriser, dvs geografisk variation). Det h칛r s칛ttet att modellera spatiellt beroende 칛r 칬verkurs[^5], s친 ni kommer att f친 g칬ra f칬ljande f칬renkling f칬r att f친nga det geografiska beroendet i medianhuspriset. Genom att anv칛nda latitud och longitud koordinaterna kan ni ber칛kna avst친ndet till en central plats i Boston. Ni kan sedan inkludera detta avst친nd som en f칬rklarande variabel i en regressionsmodell, f칬r att se om den f칬rklarar variation i medianhuspriserna.

I sista uppgiften ska ni f칬resl친 en prognosmodell f칬r medianhuspriset d칛r ni f친r v칛lja vilka f칬rklaringsvariabler ni vill ha med (ni v친r v칛lja bland en delm칛ngd av de som listas ovanf칬r, se Uppgift 5.4). Ni ska sedan anv칛nda er modell f칬r att prognostisera medianhuspriset f칬r tio censusdistrikt i datasetet `boston_districts_to_predict.Rdata` ([ladda ner](https://github.com/StatisticsSU/SDA1/blob/main/assignments/assignment1/Boston_districts_to_predict.RData?raw=true)). Det h칛r datasetet har endast de f칬rklarande variablerna, dvs alla de variabler ni f친r anv칛nda f칬rutom medianhuspriset. N칛r vi r칛ttar era inl칛mningsuppgifter kommer vi att j칛mf칬ra prognoserna mot de faktiska v칛rden (vi har tillg친ng till dessa). De tre b칛sta prognosmakarna kommer att publiceras p친 hemsidan.

Inl칛mningsuppgiften ska l칛mnas in i form av ett html dokument genererat av Quarto. **Kontrollera noga att du inte har n친gra felmeddelande och att dokumentet kompileras utan problem**. Anv칛nd tydliga figurer och namnge axlarna med tydliga variabelnamn. Gl칬m inte att skriva era namn ovanf칬r ist칛llet f칬r Namn 1, Namn 2 och Namn 3.
:::

[^1]: Kallas f칬r census survey p친 engelska. En statistisk unders칬kning d칛r hela populationen unders칬ks.

[^2]: Totalunders칬kningen trunkerade medianhusv칛rdet till 50K f칬r de censusdistrikten som l친g 칬ver. Vi har tagit bort dessa censusdistrikt. Vi har ocks친 tagit bort variabler som 칛r irrelevanta.

[^3]: Harrison Jr, D., & Rubinfeld, D. L. (1978). Hedonic housing prices and the demand for clean air. Journal of Environmental Economics and Management, 5(1), 81-102.

[^4]: Pace, R. K., & Gilley, O. W. (1997). Using the spatial configuration of the data to improve estimation. The Journal of Real Estate Finance and Economics, 14(3), 333-340.

[^5]: Forts칛tt l칛sa Statistik och Dataanalys II s친 l칛r ni er hur man g칬r detta.

## 0. Ladda in data

#### 游눩 Uppgift 0.1

St칛ll in arbetsmappen samt ladda in dataseten `Boston_census_data.Rdata` och `Boston_districts_to_predict.Rdata` (l칛nkar f칬r att ladda ner data finns i Instruktioner avsnittet ovan).

::: {.callout-note appearance="minimal"}
# Uppgift 0.1 - Svar

```{r}
##install and require packages
required_pkgs <- c("mosaic", "dplyr", "geosphere", "leaflet", "corrplot")
pkg_is_installed <- required_pkgs %in% rownames(installed.packages())
if(any(pkg_is_installed = FALSE)) {
  
  install.packages(required_pkgs[!pkg_is_installed])
}
invisible(lapply(required_pkgs, FUN = function(pkgs) {
  do.call("require", list(pkgs)) 
}))

#load boston census data
load(file = url("https://github.com/StatisticsSU/SDA1/blob/main/assignments/assignment1/Boston_census_data.RData?raw=true")) 
load(file = url("https://github.com/StatisticsSU/SDA1/blob/main/assignments/assignment1/Boston_districts_to_predict.RData?raw=true"))

```
:::

## 1. Kriminalitet i Boston

I detta avsnitt ska ni analysera kriminaliteten i Boston med hj칛lp av variabeln `crime_rate`.

#### 游눩 Uppgift 1.1

Vad kan man generellt s칛ga om kriminaliteten i censusdistrikten? Anv칛nd l칛mpliga figurer samt f칬rdelningsm친tt som underlag.

::: {.callout-note appearance="minimal"}
# Uppgift 1.1 - Svar

Histogrammet visar att f칬rdelningen f칬r crime_rate 칛r unimodal och mycket skev 친t h칬ger. Den ser dessutom ut att ha flera outliers. Boxploten bekr칛ftar skevheten, och visar dessutom vilka punkter som verkligen 칛r outliers, n칛mligen de som ligger ovanf칬r Q3 +1.5IQR, och under Q1 - 1.5IQR. Skevheten g칬r att medelv칛rdet (3.66), och medianen (0.24) skiljer sig 친t. Eftersom distributionen 칛r skev, 칛r medianen och IQR ett b칛ttre m친tt p친 distributionens mitt och spridning.

Vi utg친r ifr친n att outliers inte 칛r felskrivningar, och att de v칛rdena 칛r korrekta. Dessutom, tror vi, 칛r det dessa punker som 칛r mest intressanta n칛r man vill vet mer om brottsligheten i Boston.

Figurerna och f칬rdelningsm친tten ger oss en bild av ett mestadels fridfullt Boston, d칛r kriminaliteten 칛r koncentrerad till ett relativt f친tal omr친den, s.k. hot-spots. Varf칬r brottsligheten 칛r koncentrerad i just de omr친dena vet vi inte 칛n.

```{r}
favstats(Boston_census_data$crime_rate)
hist(Boston_census_data$crime_rate, breaks = 50)
boxplot(Boston_census_data$crime_rate, ylab = "Crime Rate")

```
:::

#### 游눩 Uppgift 1.2

Varierar brottsligheten i Boston beroende p친 den kategoriska variabeln `town`? Det finns 88 olika utfall av `town` (dvs 88 olika stadsdelar). V칛lj ut `Boston East Boston`, `Boston Downtown`,`Cambridge`, samt tv친 valfria stadsdelar f칬r att besvara fr친gan. Fr친gan besvaras med hj칛lp av l칛mpligt valda figurer och statistiska m친tt.

::: callout-tip
Skapa en ny data frame som filtrerar `Boston_census_data` (till exempel genom `filter()` funktionen) utefter de stadsdelarna ni 칛r intresserade utav innan ni p친b칬rjar analysen.
:::

::: {.callout-note appearance="minimal"}
# Uppgift 1.2 - Svar

Boxplotten visar ett klart samband mellan town och crime_rate.

S칛rskilt Cambridge utm칛rker sig som s칛rskilt fridfullt j칛mf칬rt med andra towns. Cambridge har en l친g median p친 ungef칛r 3 brott per 1000 people, liten spridning, och endast en enda outlier som ligger hyfsat n칛ra .

Downton Boston har h칬gst medianv칛rde, och kvartilerna ligger h칬gre 칛n motsvarande kvartiler alla andra towns.

```{r}
selected_towns <- c("Boston East Boston", "Boston Downtown", "Cambridge", "Boston Roxbury", "Boston Savin Hill")
town_subset <- Boston_census_data %>%
  filter(town %in% selected_towns)
boxplot(crime_rate ~ town, data = town_subset)
```
:::

#### 游눩 Uppgift 1.3

Vilka tre variabler i datasetet `Boston_census_data` korrelerar mest med brottslighet? Beskriv det parvisa sambandet mellan brottslighet och vardera av dessa tre variabler.

::: callout-tip
Kom ih친g att korrelation 칛r ett beroendem친tt f칬r *numeriska variabler*.
:::

::: {.callout-note appearance="minimal"}
# Uppgift 1.3 - Svar

Eftersom korrelation bara 칛r giltig f칬r numeriska variabler tog vi f칬rst bort de som R ans친g vara kategoriska med hj칛lp av funktionen 'select_if(is.numeric)'.

Sedan tog vi 칛ven bort variabeln 'border_charles', som 칛r en dummy-variabel, och allts친 inte 칛r numerisk.

Tabellen visat att de tre variabler som har h칬gst korrelation med crime_rate 칛r

-   radial_access (0.62)

-   tax_rate (0.58)

-   lower_stat_pct (0.46)

Om vi plottar variablerna mot varandra (crime rate 칛r i log-skala f칬r att tydligare representera data) ser vi ett linj칛rt samband mellan variablerna.

```{r}
strictly_numerical <- Boston_census_data %>%
  select_if(is.numeric) %>%
  select(-any_of(c("borders_charles"))) 

correlations <- cor(strictly_numerical)
sorted_crime_rate_correlations <- sort(correlations[,4])
sorted_crime_rate_correlations

plot(log(crime_rate) ~ radial_access, data = Boston_census_data)
plot(log(crime_rate) ~ tax_rate, data = Boston_census_data)
plot(log(crime_rate) ~ lower_stat_pct, data = Boston_census_data)

```
:::

## 2. Fastighetsskatt i Boston

I detta avsnitt ska ni analysera fastighetsskatten i Boston med hj칛lp av variabeln `tax_rate`.

#### 游눩 Uppgift 2.1

Vad kan man generellt s칛ga om fastighetsskatten i censusdistrikten? Anv칛nd l칛mpliga figurer samt f칬rdelningsm친tt som underlag.

::: {.callout-note appearance="minimal"}
# Uppgift 2.1 - Svar

Histogrammet visar hur stor andel av distrikten som betalar en viss fastighetsskatt.

Distributionen av fastighetsskatten verkar vara bimodal (kanske till och med multimodal), med en topp strax 칬ver 300 per 10000 USD och en annan topp p친 660 per 10000 USD. Mellan topparna 칛r det en stor glipa.

Multimodaltiteten g칬r att det blir sv친rt att uttala sig om distributionen. Det 칛r t.ex lite oklart vilken form distributionen har, och vi kan inte s칛ga om den t.ex 칛r normalformad eller skev. Dessutom hamnar medianen (330) och medelv칛rdet (409) mitt i en dal, och allts친 skulle distributionen ha ett l칛gesm친tt som ingen av v칛rden ligger i n칛rheten av. Multimodaliteten ger oss ocks친 problem n칛r vi vill se p친 spridningen - t.ex s친 ligger IQR till h칛lften i ett omr친de utan n친gra v칛rden alls.

H칛r skulle det nog varea klokt att dela upp i kategorier, och p친 s친 s칛tt bli av med multimodaliteten. Det skulle f칬rmodligen vara enklare och b칛ttre att analysera distributionerna av de enskilda kategorierna.

```{r}
histogram(Boston_census_data$tax_rate, breaks = 100)
boxplot(Boston_census_data$tax_rate, ylab = "Tax Rate")
favstats(Boston_census_data$tax_rate)

```
:::

#### 游눩 Uppgift 2.2

L친t oss skapa en ny variabel `cat_tax` som anger om ett censusdistrikt betalar l친g (`low`), medel (`medium`), eller h칬g (`high`) fastighetsskatt. Vi definerar skattekategorierna enligt

-   `low`: `tax_rate` $\leq$ 250,
-   `medium`: 250 $<$ `tax_rate` $\leq$ 400,
-   `high`: `tax_rate` $>$ 400.

F칬ljande kod skapar och l칛gger till variabeln `cat_tax` i `Boston_census_data`

```{r}
Boston_census_data$cat_tax <- cut(Boston_census_data$tax_rate, 
              breaks=c(0, 250, 400, 800),
              labels=c('Low', 'Medium', 'High'))
```

Finns det ett samband mellan vilken skattekategori ett censusdistrikt tillh칬r och dess angr칛nsning till Charles River? F칬rklara med hj칛lp av l칛mplig tabell samt figur.

::: {.callout-note appearance="minimal"}
# Uppgift 2.2 - Svar

Vi undrar vad andelen av varje skattekategori 칛r givet borders_charles. Tabellen och figuren visar endast ett svagt samband mellan vilken skattekategori ett distrikt har, och dess angr칛nsning till Charles River. De distrikt som ligger i anslutning till Charles 칛r oftare i skattekategorin "medium" 칛n de distrikt som inte ligger n칛ra Charles. D칛rmed f칬ljer att f칬rdelningen av distrikt som inte ligger n칛ra Charles har en h칬gre andel observationer i "high" och "low" skattekategorin.

```{r}

t <- tally(~ cat_tax | borders_charles, data = Boston_census_data, format = "percent")
t
barplot(t, col = c("aquamarine", "cornflowerblue", "darkblue"), xlab = "borders charles", legend=c("low", "medium", "high"), las=2)

```
:::

#### 游눩 Uppgift 2.3

Hur m친nga procent av alla censusdistrikt ligger i angr칛nsning till Charles River och tillh칬r en h칬g skattekategori? Hur stor andel av censusdistrikten med h칬g skatt ligger inte i angr칛nsning till Charles River?

::: {.callout-note appearance="minimal"}
# Uppgift 2.3 - Svar

Eftersom f칬rsta fr친gan handlar om procentandelen av ALLA censusdistrikt, kan vi avl칛sa svaret i tabellen med tabellprocent. Vi ser att 2.1% av alla censusdistrikt ligger i angr칛nsning till Charles River och tillh칬r en h칬g skattekategori

Andra fr친gan handlar om procentandelen betingat p친 skattekategori. D칛rf칬r kan vi avl칛sa svaret i tabellen med kolumnprocent. Vi ser att 94.7% av censusdistrikten med h칬g skatt inte ligger i angr칛nsning till Charles River.

```{r}
tally(~ cat_tax & borders_charles, data = Boston_census_data, margins = TRUE, format = "percent")
tally(~ borders_charles | cat_tax, data = Boston_census_data, margins = TRUE, format = "percent")
```
:::

#### 游눩 Uppgift 2.4

Vilka tv친 variabler i datasetet `Boston_census_data` korrelerar mest med `tax_rate`? Beskriv det parvisa sambandet mellan `tax_rate` och vardera av dessa tv친 variabler. 츿r dessa korrelationssamband eller kausala samband?

::: callout-tip
Kom ih친g att korrelation 칛r ett beroendem친tt f칬r *numeriska variabler*.
:::

::: {.callout-note appearance="minimal"}
# Uppgift 2.4 - Svar

Som f칬rut tar vi bort alla icke-numeriska variabler och borders_charles. I tabellen kan vi avl칛sa att de tv친 variablerna som korrelerar mest med tax_rate 칛r:

-   radial_acces (0.91)

-   indust_p (0.72)

```{r}
strictly_numerical <- Boston_census_data %>%
  select_if(is.numeric) %>%
  select(-any_of(c("borders_charles"))) 

correlations <- cor(strictly_numerical)
sorted_crime_rate_correlations <- sort(correlations[,12])
sorted_crime_rate_correlations
plot(radial_access ~ tax_rate, data = Boston_census_data)
plot(indust_p ~ tax_rate, data = Boston_census_data)
```

Vi kan inte genom enbart korrelation bevisa n친got kausalt samband i n친gon av dessa fall.
:::

## 3. Avst친nd till Fenway park

I detta avsnitt ska ni skapa en ny variabel som m칛ter avst친ndet till Fenway park (stadion d칛r basebollslaget Boston Red Sox spelar sina hemmamatcher). Genom variablerna `latitude` och `longitude` kan vi ber칛kna det s친 kallade cirkelavst친ndet[^6] till Fenway park f칬r varje distrikt. Formeln f칬r cirkelavst친ndet 칛r ganska komplicerad, men den finns implementerad i funktionen `distHaversine()` i R-paketet `geosphere`. F칬ljande kod ber칛knar avst친ndet till Fenway park f칬r varje censusdistrikt och sparar den som en ny variabel `dist_fenway_park` i `Boston_census_data`.

[^6]: Ett avst친nd mellan tv친 punkter uttryckta i latitud och longitud koordinater som tar h칛nsyn till att jorden 칛r rund. Se [h칛r](https://en.wikipedia.org/wiki/Haversine_formula) f칬r detaljer.

```{r}
library(geosphere) # Install if not available
lat_long <- cbind(Boston_census_data$latitude, Boston_census_data$longitude)
fenway_park_lat_long <- c(42.346462, -71.097250) # latitude and longitude for Fenway_park
Boston_census_data$dist_fenway_park <- distHaversine(lat_long, fenway_park_lat_long)
```

Vi kan visualisera Fenway park samt censusdistrikten i en interaktiv karta med hj칛lp av R-paketet `leaflet`. F칬ljande kod visualiserar Fenway park samt censusdistrikten f칬r observationerna 30 och 45.

```{r}

library(leaflet) # Install if not available
Boston_map <- leaflet() %>% 
  addTiles() %>%
  addMarkers(lat = fenway_park_lat_long[1], lng = fenway_park_lat_long[2], popup="Fenway park") %>%
  addMarkers(lat = Boston_census_data$latitude[30], lng = Boston_census_data$longitude[30], popup="Observation 30") %>%
  addMarkers(lat = Boston_census_data$latitude[45], lng = Boston_census_data$longitude[45], popup="Observation 45") 

Boston_map # Show interactive map

```

#### 游눩 Uppgift 3.1

G칬r ett histogram f칬r variabeln `dist_fenway_park`. Vilket av censusdistrikten har l칛ngst respektive kortast avst친nd till Fenway park? Markera ut dessa distrikt i en interaktiv karta tillsammans med Fenway park.

::: callout-tip
N칛r ni vet vad det l칛ngsta respektive kortaste avst친ndet 칛r s친 kan ni anv칛nda `filter()` funktionen f칬r att filtrera `Boston_census_data` p친 ett l칛mpligt s칛tt.
:::

::: {.callout-note appearance="minimal"}
# Uppgift 3.1 - Svar

Distriktet med kortast avst친nd fr친n Fenway Park 칛r Wilmington, med en distans p친 887 distanenheter.

Distriktet med l칛ngst avst친nd fr친n Fenway Park 칛r Marshfield, med en distans p친 33638 distansenheter.

```{r}
library(geosphere) # Install if not available
lat_long <- cbind(Boston_census_data$latitude, Boston_census_data$longitude)
fenway_park_lat_long <- c(42.346462, -71.097250) # latitude and longitude for Fenway_park
Boston_census_data$dist_fenway_park <- distHaversine(lat_long, fenway_park_lat_long)

histogram(~ dist_fenway_park, data = Boston_census_data, breaks = 50)

dist_fenway_park_min <- min(~ dist_fenway_park, data = Boston_census_data)
dist_fenway_park_max <- max(~ dist_fenway_park, data = Boston_census_data)
closest_district_to_fenway_park <- filter(Boston_census_data, dist_fenway_park == dist_fenway_park_min)
farthest_district_from_fenway_park <- filter(Boston_census_data, dist_fenway_park == dist_fenway_park_max)
#Distriktet med kortast avst친nd = Wilmington med en distans p친 887.
#Distriktet med l칛ngst avst친nd = Marshfield med en distans p친 33638.

#Draw interactive map
library(geosphere) 
lat_long <- cbind(Boston_census_data$latitude, Boston_census_data$longitude)
fenway_park_lat_long <- c(42.346462, -71.097250) # latitude and longitude for Fenway_park
Boston_census_data$dist_fenway_park <- distHaversine(lat_long, fenway_park_lat_long)

library(leaflet) 
Boston_map <- leaflet() %>% 
  addTiles() %>%
  addMarkers(lat = fenway_park_lat_long[1], lng = fenway_park_lat_long[2], popup="Fenway park") %>%
  addMarkers(lat = closest_district_to_fenway_park$latitude[1], lng = closest_district_to_fenway_park$longitude[1], popup = closest_district_to_fenway_park$town) %>%
  addMarkers(lat = farthest_district_from_fenway_park$latitude[1], lng = farthest_district_from_fenway_park$longitude[1], popup = farthest_district_from_fenway_park$town)

Boston_map # Show interactive map

```
:::

#### 游눩 Uppgift 3.2

Finns det ett samband mellan `dist_fenway_park` och `median_home_value`?

::: {.callout-note appearance="minimal"}
# Uppgift 3.2 - Svar

Vi ser en mycket svag korrelation, med styrkan -0.002. Plotten visar inte heller n친got samband, s친 vi kan med ganska god s칛kerhet s칛ga att det inte finns n친got meningsfullt samband mellan de tv친 variablerna, annat 칛n att variationen p친 median home value tycks vara st칬rre n칛rmare Fenway Park.

```{r}
cor(Boston_census_data$median_home_value, Boston_census_data$dist_fenway_park)

plot(Boston_census_data$dist_fenway_park, Boston_census_data$median_home_value)

```
:::

#### 游눩 Uppgift 3.3

Finns det ett samband mellan `dist_fenway_park` och `crime_rate`?

::: {.callout-note appearance="minimal"}
# Uppgift 3.3 - Svar

Det finns en negativ korrelation med en styrka p친 ca -0.1228. D친 brottslighet 칛r mycket l친g i majoritet av distrikten 칛r plotten d칛remot sv친r att avl칛sa: i de allra flesta fall beg친s n칛stan inga brott alls. D칛remot verkar alla distrikt med en brottslighet \> ca 3 ligga mellan 5000-10 000 distansenheter fr친n fenway park. Det finns allts친 ett mycket tydligt samband som ej reflekteras i korrelationskoficienten.

```{r}
cor(Boston_census_data$crime_rate, Boston_census_data$dist_fenway_park)
plot(Boston_census_data$crime_rate, Boston_census_data$dist_fenway_park)

```
:::

## 4. Enkel linj칛r regression

I detta avsnitt ska ni anpassa och tolka n친gra enkla linj칛ra regressionsmodeller.

#### 游눩 Uppgift 4.1

Anpassa en linj칛r regression med responsvariabel `NOx` och f칬rklarande variabel `employ_dist`. Rita den anpassade regressionslinjen tillsammans med data i en l칛mplig figur. Beskriv resultaten och tolka modellen. Utf칬r en modellvalidering via en residualanalys och kommentera modellens l칛mplighet. Om modellen inte anses l칛mplig, vilka antaganden har inte varit uppfyllda?

::: {.callout-note appearance="minimal"}
# Uppgift 4.1 - Svar

Punktdiagrammet visar ett negativ, icke-linj칛rt samband mellan NOx och employ_dist. Regressionslinjen ser inte ut att passa s친 bra, eftersom den 칛r rak, och sambandet inte 칛r linj칛rt.

```{r}
fit <- lm(NOx ~ employ_dist, data = Boston_census_data)
plot(NOx ~ employ_dist, data = Boston_census_data)
abline(fit)
```

Residualanalysen bekr칛ftar v친ra farh친gor om den linj칛ra regressionens l칛mplighet. Normal Q-Q plotten visar att de standardiserade residualern inte f칬ljer en rak linje med 45 graders vinkel. Detta 칛r ett tecken p친 att modellen inte 칛r v칛l anpassad, eftersom residualerna inte 칛r normalf칬rdelade.

I Residuals vs Fitted syns ett (icke linj칛rt) samband mellan residualerna och fitted values. Detta 칛r ett tecken p친 att sambandet mellan NOx och employ_dist inte 칛r linj칛rt. Dessutom uppvisar den heteroscedasticitet, dvs att residualerna blir st칬rre l칛ngre 친t h칬ger.

Sist tittar vi p친 residuals vs. leverage. Vi letar efter outliers med h칬g residual och h칬g leverage, eftersom de har stor effekt p친 modellen. S칛rskilt observationerna 125 och 130 verkar vara s칛rskilt inflytelserika. Kanske skulle modellen bli b칛ttre om de togs bort.

칐verlag 칛r det en d친lig modell, f칬r ingen av antagandena verkar vara uppfyllda.

```{r}
par(mfrow = c(2, 2))
plot(fit)
par(mfrow = c(1, 1))
```
:::

#### 游눩 Uppgift 4.2

Anv칛nd modellen i Uppgift 4.1 f칬r att prediktera genomsnittsutsl칛ppet f칬r observation 10 med `employ_dist`=10.5857 och ber칛kna dess residual.

::: {.callout-note appearance="minimal"}
# Uppgift 4.2 - Svar

Det predikterade v칛rdet f칬r employ_dist = 10.5857 칛r 0.266 NOx.

Det observerade v칛rdet 칛r 0.413 NOx.

Residualen 칛r -0.147.

```{r}
new_x <- data.frame(employ_dist = c(Boston_census_data[10,12]))
predicted <- predict(fit, newdata = new_x)
predicted
observed <- Boston_census_data[10,9]
residual <- predicted - observed
residual


```
:::

#### 游눩 Uppgift 4.3

Anv칛nd Tukeys cirkel f칬r att transformera variablerna i Uppgift 4.1 (avg칬r sj칛lv vilken eller vilka av de tv친 som beh칬ver transformeras). Anpassa en ny linj칛r regression p친 de transformerade data. Utf칬r en modellvalidering (efter transformation) via en residualanalys och kommentera modellens l칛mplighet j칛mf칬rt med modellen i Uppgift 4.1. Plotta den anpassade regressionen i icke-transformerad skala tillsammans med data (ocks친 i icke-transformerad skala) i en l칛mplig figur.

::: callout-tip
T칛nk p친 att ta h칛nsyn till eventuella transformationer!
:::

::: {.callout-note appearance="minimal"}
# Uppgift 4.3 - Svar

Vi 칛r i nedre v칛nstra h칬rnet p친 tukeys cirkel och kan d칛rf칬r g친 ner친t i trappan med antingen x eller y eller med b친de x och y. Vi g칬r f칬ljande tv친 transformationer:

$$x \Rightarrow \sqrt{x}$$

$$
y \Rightarrow -y^{-\frac{1}{2}}
$$

Och f친r en scatterplot som visar ett rakare samband.

```{r}
fit2 <- lm(I(-NOx^(-1/2)) ~ sqrt(employ_dist), data = Boston_census_data)

plot(I(-NOx^(-1/2)) ~ sqrt(employ_dist), data = Boston_census_data)


#/
transformed_y_hat <- predict(fit2) # transformed scale prediction
y_hat <- ((transformed_y_hat * -1)^(-1/2))^2 #original scale prediction
head(transformed_y_hat)

head(y_hat)

plot(NOx ~ employ_dist, data = Boston_census_data, col = "cornflowerblue")# Data on original scale
lines(Boston_census_data$employ_dist, y_hat, type = "p", col = "lightcoral")
legend(x = "topleft", pch = c(1, 1), col = c("cornflowerblue", "lightcoral"), legend=c("Data", "Predicted"))


```

Residualerna visar en f칬rb칛ttring, men det 칛r 칛nnu inte perfekt. Normal Q-Q plotten f칬ljer den diagonala raka linjen n친got b칛ttre, men de standardiserade residualerna 칛r fortfarande f칬r h칬ga f칬r h칬ga och l친ga v칛rden.

Vi ser att modellen inte g칬r ett bra jobb med att predicera data n칛r vi j칛mf칬r den emot data i originalskala.

\# residual vs. fitted visar endast ett svagt icke-linj칛rt samband, som 칛r b칛ttre 칛n tidigare.

```{r}
par(mfrow = c(2, 2))
plot(fit2)
par(mfrow = c(1, 1))
```
:::

#### 游눩 Uppgift 4.4

Anv칛nd modellen i Uppgift 4.3 f칬r att prediktera genomsnittsutsl칛ppet f칬r observation 10 med `employ_dist`=10.5857 och ber칛kna dess residual. Kommentera resultaten j칛mf칬rt med Uppgift 4.2.

::: callout-tip
T칛nk p친 att ta h칛nsyn till eventuella transformationer!
:::

::: {.callout-note appearance="minimal"}
# Uppgift 4.4 - Svar

Residualen f칬r modellen i 4.3 칛r ca 0.1848. F칬r modellen i Uppgift 2 칛r residualen -0.147. Modellen i uppgift 4.2 kom allts친 n칛rmare en modellen i uppgift 4.3

```{r}
NOx_hat_transformed <- predict(fit2,newdata = data.frame(employ_dist = 10.5857))
NOx_hat <- (1/sqrt(NOx_hat_transformed * -1))^2
residual <- NOx_hat - Boston_census_data[10, 9]
residual
```
:::

## 5. Multipel linj칛r regression

I detta avsnitt ska ni studera multipel linj칛ra regression.

#### 游눩 Uppgift 5.1

Anpassa en linj칛r regression med responsvariabel logaritmerad `median_home_value` samt f칬rklarande variabler `lower_stat_pct` och dummy-variabeln `borders_charles`. Tolka koefficienten f칬r `borders_charles`.

::: {.callout-note appearance="minimal"}
# Uppgift 5.1 - Svar

```{r}
median_home_model <- lm(log(median_home_value) ~ lower_stat_pct + borders_charles, data = Boston_census_data)
summary(median_home_model)
```

Koefficienten f칬r borders_charles, ger oss v칛rdet 0.134560. V칛rdet av det predicerade medianpriset f칬r ett hus, givet att `lower_stat_pct` 칛r konstant, b칬r 칬ka med ca 13.45% om huset ligger i ett distrikt som angr칛nsar Charles.
:::

#### 游눩 Uppgift 5.2

Anpassa en linj칛r regression med responsvariabel `NOx` samt f칬rklarande variabler `lower_stat_pct` och dummy-variabeln `borders_charles`. Vad tror ni om den statistiska signifikansen f칬r respektive f칬rklarande variabel?

::: {.callout-note appearance="minimal"}
# Uppgift 5.2 - Svar

Skriv svaret h칛r.

```{r}
NOx_Model <- lm(NOx ~ lower_stat_pct + borders_charles, data = Boston_census_data)
summary(NOx_Model)
```

F칬r variabeln lower_stat_pct 칛r den statistiska signifikansen \<2e-16, vilket 칛r mycket l친gt. Oddsen att det handlar om slumpen och inte ett faktiskt samband 칛r mycket l친gt.

F칬r variabeln borders_charles 칛r den statistiska signifikansen 0.0145, vilket 칛r h칬gre. Oddsen att det handlar om slumpen och inte ett faktiskt samband 칛r ca 1.45%, vilket 칛r ganska h칬gt beroende p친 sammanhanget. D칛remot tror vi att resultatet fortfarande 칛r statistiskt signifikant.
:::

#### 游눩 Uppgift 5.3

Anv칛nd modellen i Uppgift 5.1 f칬r att prediktera `median_home_value` f칬r observation 30 och ber칛kna dess residual.

::: callout-tip
T칛nk p친 att ta h칛nsyn till log-transformationen i den anpassade modellen!
:::

::: {.callout-note appearance="minimal"}
# Uppgift 5.3 - Svar

```{r}
observation_30 <- data.frame(Boston_census_data[30, ])
observation_30_hat <- predict(median_home_model, observation_30)
exp(observation_30_hat)
```

Det predicerade v칛rdet, transformerat till sin y-skala, 칛r 24.61193. Residualen f칬r det predicerade v칛rdet blir d친 (22 - 24.61193 = 2.6111193)
:::

#### 游눩 Uppgift 5.4

Ni ska nu utveckla en prognosmodell f칬r medianhuspriset `median_home_value`. Ni f친r endast v칛lja mellan f칬ljande f칬rklarande variabler samt godtyckliga transformationer av dom (ni f친r 칛ven transformera responsen):

-   `before_1940_p`
-   `crime_rate`
-   `radial_access`
-   `NOx`
-   `dist_fenway_park` (som skapades i Avsnitt 3).

Det finns $2^5 = 32$ olika s칛tt att inkludera de olika f칬rklarande variabler och d칛rmed 32 olika modeller man kan testa, plus i princip hur m친nga som helst om vi ocks친 transformerar. Vi f칬rv칛ntar oss naturligtvis inte att ni g친r igenom varje m칬jlig modell, men vi f칬ruts칛tter att ni testar er fram metodiskt.

F칬r att utv칛rdera mellan olika modeller kan ni anv칛nda justerat R-kvadrat samt korsvalidering med 4 folds. **Sortera inte \``boston_census_data.Rdata` slumpm칛ssigt n칛r ni korsvaliderar (data ligger redan i slumpm칛ssig ordning)**. Dela upp datasetet i fyra delar n칛r ni korsvaliderar (del 1: observationer 1-120, del 2: observationer 121-240, del 3: observationer 241-360, del 4: observationer 361-480).

::: callout-tip
T칛nk p친 att ta h칛nsyn till eventuell transformation av responsvariabeln n칛r ni utf칬r korsvalideringen. Korsvalideringen anv칛nder prediktionen $\hat{y}$ som 칛r prediktionen av $y$. Exempelvis, om ni har valt transformationen $\log(y)$ 칛r modellens prediktion av responsen $\widehat{\log(y)}$. N칛r ni korsvaliderar blir d친 $\hat{y}=\exp\left(\widehat{\log(y)}\right)$ prediktionen av $y$.

Om ni anv칛nder `reg_crossval()` funktionen fr친n kurspaketet `sdakurs` t칛nk d친 p친 tv친 saker:

-   Anv칛nd argumentet `obs_order = 1:480` f칬r att inte sortera data slumpm칛ssigt.
-   Funktionen kan inte hantera en transformerad respons.

Vill man transformera responsen kan man f칬lja korsvalideringsexemplet (med transformerad respons) i Lab 4.
:::

::: {.callout-note appearance="minimal"}
# Uppgift 5.4 - Svar

Vi plottar f칬rst de olika f칬rklarande variablerna emot median_home_value f칬r att se hur l칛mpliga de enskilda distributionerna var att anv칛nda till en linj칛r regression. Vi kollade om de var linj칛ra nog.

```{r}
plot(Boston_census_data$before_1940_p, Boston_census_data$median_home_value)
plot(Boston_census_data$crime_rate, Boston_census_data$median_home_value)
plot(Boston_census_data$radial_access, Boston_census_data$median_home_value)
plot(Boston_census_data$NOx, Boston_census_data$median_home_value)
plot(Boston_census_data$dist_fenway_park, Boston_census_data$median_home_value)

multipleModel <- lm(median_home_value ~ crime_rate + before_1940_p+ NOx + dist_fenway_park, data = Boston_census_data)
summary(multipleModel)


```

Vi plottade de enskilda variablerna mot median_home_value f칬r att se om d칛r var n친gra icke-linj칛ra samband. Vi m칬rkte att before_1940_p var n친got b칬jd och gjorde en transformation med y =\> y\^2. Vi s친g ocks친 att variabeln crime_rate var skev och transformerade den till log-skala. Slutligen kvadrerade vi variabeln NOx och tog roten ur variabeln dist_fenway_park f칬r att f친 n친got mindre skev data.

```{r}

par(mfrow = c(1, 2))
plot(median_home_value ~ before_1940_p, data = Boston_census_data)
plot(median_home_value ~ I(before_1940_p^2), data = Boston_census_data)
par(mfrow = c(1, 1))

par(mfrow = c(1, 2))
plot(median_home_value ~ crime_rate, data = Boston_census_data)
plot(median_home_value ~ log(crime_rate), data = Boston_census_data)
par(mfrow = c(1, 1))

par(mfrow = c(1, 2))
plot(median_home_value ~ NOx, data = Boston_census_data)
plot(median_home_value ~ I(NOx^2), data = Boston_census_data) #original is better
par(mfrow = c(1, 1))

par(mfrow = c(1, 2))
plot(median_home_value ~ dist_fenway_park, data = Boston_census_data)
plot(median_home_value ~ sqrt(dist_fenway_park), data = Boston_census_data) #original is same
par(mfrow = c(1, 1))
```

```{r}

multipleModel2 <- lm(median_home_value ~ I(before_1940_p^2) + log(crime_rate) + NOx + dist_fenway_park, data = Boston_census_data)
summary(multipleModel2)
```

Vi s친g en liten f칬rb칛ttring av Adjusted R-squared till f칬ljd av transformationerna, fr친n 0.3988 till 0.4013. Vi korsvaliderar nu v친ran modell.

```{r}
#Crossvalidation for our non-transformed model

n <- 480 # Number of observations
# Fold 1:
obs_index <- c(1:n) # Keeps track of the indices of  the dataset (1, 2, 3, ...., n = 125)
test_fold_index <- obs_index[c(1:120)] # Subsets indices 1:25 (test data fold 1) 
training_fold_index <- obs_index[-c(1:120)] # Takes out the complement
lm_modell1_fold1 <- lm(median_home_value ~ before_1940_p + crime_rate + NOx + dist_fenway_park, subset = training_fold_index, data = Boston_census_data) # Estimate fold 1
test_data <- Boston_census_data[test_fold_index, ] # Create test data for fold
y_hat_fold1 <- predict(lm_modell1_fold1, newdata = test_data) # Predict test data in sqrt scale
SSE_fold1 <- sum((test_data$median_home_value - y_hat_fold1)^2) 

# Fold 2:
test_fold_index <- obs_index[c(121:240)] 
training_fold_index <- obs_index[-c(121:240)] 
lm_modell1_fold2 <- lm(median_home_value ~ before_1940_p + crime_rate + NOx + dist_fenway_park, subset = training_fold_index, data = Boston_census_data)
test_data <- Boston_census_data[test_fold_index, ]
y_hat_fold2 <- predict(lm_modell1_fold2, newdata = test_data) 
SSE_fold2 <- sum((test_data$median_home_value - y_hat_fold2)^2) 

# Fold 3:
test_fold_index <- obs_index[c(241:360)] 
training_fold_index <- obs_index[-c(241:360)] 
lm_modell1_fold3 <- lm(median_home_value ~ before_1940_p + crime_rate + NOx + dist_fenway_park, subset = training_fold_index, data = Boston_census_data) 
test_data <- Boston_census_data[test_fold_index, ]
y_hat_fold3 <- predict(lm_modell1_fold3, newdata = test_data) 
SSE_fold3 <- sum((test_data$median_home_value - y_hat_fold3)^2) 

# Fold 4:
test_fold_index <- obs_index[c(241:360)]
training_fold_index <- obs_index[-c(361:480)]
lm_modell1_fold4 <- lm(median_home_value ~ before_1940_p + crime_rate + NOx + dist_fenway_park, subset = training_fold_index, data = Boston_census_data) 
test_data <- Boston_census_data[test_fold_index, ] 
y_hat_fold4 <- predict(lm_modell1_fold4, newdata = test_data) 
SSE_fold4 <- sum((test_data$median_home_value - y_hat_fold4)^2) 


#Crossvalidation for the model without transformations
n <- 480 # Number of observations
# Fold 1:
obs_index <- c(1:n) # Keeps track of the indices of  the dataset (1, 2, 3, ...., n = 125)
test_fold_index <- obs_index[c(1:120)] # Subsets indices 1:25 (test data fold 1) 
training_fold_index <- obs_index[-c(1:120)] # Takes out the complement
lm_modell1_fold1 <- lm(median_home_value ~ I(before_1940_p) + log(crime_rate) + NOx + dist_fenway_park, subset = training_fold_index, data = Boston_census_data) # Estimate fold 1
test_data <- Boston_census_data[test_fold_index, ] # Create test data for fold
y_hat_fold1 <- predict(lm_modell1_fold1, newdata = test_data) # Predict test data in sqrt scale
SSE_fold1_transformed <- sum((test_data$median_home_value - y_hat_fold1)^2)

# Fold 2:
test_fold_index <- obs_index[c(121:240)] 
training_fold_index <- obs_index[-c(121:240)] 
lm_modell1_fold2 <- lm(median_home_value ~ I(before_1940_p^2) + log(crime_rate) + NOx + dist_fenway_park, subset = training_fold_index, data = Boston_census_data)
test_data <- Boston_census_data[test_fold_index, ]
y_hat_fold2 <- predict(lm_modell1_fold2, newdata = test_data) 
SSE_fold2_transformed <- sum((test_data$median_home_value - y_hat_fold2)^2) 

# Fold 3:
test_fold_index <- obs_index[c(241:360)] 
training_fold_index <- obs_index[-c(241:360)] 
lm_modell1_fold3 <- lm(median_home_value ~ I(before_1940_p^2) + log(crime_rate) + NOx + dist_fenway_park, subset = training_fold_index, data = Boston_census_data) 
test_data <- Boston_census_data[test_fold_index, ]
y_hat_fold3 <- predict(lm_modell1_fold3, newdata = test_data) 
SSE_fold3_transformed <- sum((test_data$median_home_value - y_hat_fold3)^2) 

# Fold 4:
test_fold_index <- obs_index[c(241:360)]
training_fold_index <- obs_index[-c(361:480)]
lm_modell1_fold4 <- lm(median_home_value ~ I(before_1940_p^2) + log(crime_rate) + NOx + dist_fenway_park, subset = training_fold_index, data = Boston_census_data) 
test_data <- Boston_census_data[test_fold_index, ] 
y_hat_fold4 <- predict(lm_modell1_fold4, newdata = test_data) 
SSE_fold4_transformed <- sum((test_data$median_home_value - y_hat_fold4)^2) 


#RMSE
sqrt((1/n) * (sum(SSE_fold1, SSE_fold2, SSE_fold3, SSE_fold4)))
sqrt((1/n) * (sum(SSE_fold1_transformed, SSE_fold2_transformed, SSE_fold3_transformed, SSE_fold4_transformed)))
```

Vi s친g ocks친 en liten f칬rb칛ttring i RMSE, fr친n 5.6556 till 5.567. V친ran modell 칛r allts친 lite b칛ttre 칛n om vi enbart hade haft alla v칛rden i originalskala.
:::

游눩 Uppgift 5.5

G칬r en residualanalys av den valda modellen i Uppgift 5.3.

::: {.callout-note appearance="minimal"}
# Uppgift 5.5 - Svar

```{r}
resid <- residuals(multipleModel2)
head(resid)
plot(multipleModel2$fitted.values, resid, xlab = "yhatt", ylab = "Residuals")
```
:::

Vi ser att n칛r vi plottar residualer mot yhatt ser vi en viss kon-form, vilket inte 칛r optimalt, eftersom det tyder p친 att variansen inte 칛r konstant. Vi ser inte heller n친got tydligt samband uppst친 mellan residualerna och det predicerade v칛rdet, vilket 칛r ett gott tecken. Det ser allts친 helt okej ut att forts칛tta som vi gjort med att f칬rb칛ttra modellen h칛rifr친n.

```{r}
qqnorm(resid)
qqline(resid)

```

Vi ser p친 v친ran qqplot att den 칛r hyfsat linj칛r, och ser bra ut mellan -1 och 1. D칛refter blir den snabbt mycket s칛mre d칛refter. Vi hittade inget s칛tt att fixa detta p친,

#### 游눩 Uppgift 5.6

Anv칛nd modellen i Uppgift 5.4 f칬r att prediktera medianhuspriset f칬r observationerna i datasetet `Boston_districts_to_predict.RData`. Skriv ut resultatet s친 att vi enkelt kan j칛mf칬ra dina prognoser n칛r vi r칛ttar.

::: callout-tip
T칛nk p친 att ta h칛nsyn till eventuella transformationer av de f칬rklarande variablerna! Om ni har `dist_fenway_park` med i er prognosmodell beh칬ver ni r칛kna ut dess v칛rde f칬r observationerna i datasetet `Boston_districts_to_predict.RData` (genom att anv칛nda latitud och longitud variablerna s친som i Avsnitt 3).
:::

::: {.callout-note appearance="minimal"}
# Uppgift 5.6 - Svar

Skriv svaret h칛r.

```{r}
#Fix Boston_districts_to_predict
lat_long <- cbind(Boston_districts_to_predict$latitude, Boston_districts_to_predict$longitude)
fenway_park_lat_long <- c(42.346462, -71.097250) # latitude and longitude for Fenway_park
Boston_districts_to_predict$dist_fenway_park <- distHaversine(lat_long, fenway_park_lat_long)

prediction <- predict(multipleModel2, Boston_districts_to_predict)
data.frame(prediction)
```
:::
